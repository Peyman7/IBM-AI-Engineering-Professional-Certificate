{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldf_b3bGtp7q"
      },
      "source": [
        "<a href=\"http://cocl.us/pytorch_link_top\">\n",
        "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/Pytochtop.png\" width=\"750\" alt=\"IBM Product \">\n",
        "</a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSgM0RFMtp7s"
      },
      "source": [
        "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork/image/IDSN-logo.png\" width=\"200\" alt=\"cognitiveclass.ai logo\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uU3gQ02Ltp7s"
      },
      "source": [
        "<h1><h1>Pre-trained-Models with PyTorch </h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orVbjgYztp7t"
      },
      "source": [
        "In this lab, you will use pre-trained models to classify between the negative and positive samples; you will be provided with the dataset object. The particular pre-trained model will be resnet18; you will have three questions:\n",
        "<ul>\n",
        "<li>change the output layer</li>\n",
        "<li> train the model</li>\n",
        "<li>  identify  several  misclassified samples</li>\n",
        " </ul>\n",
        "You will take several screenshots of your work and share your notebook.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOFyTR0Ntp7t"
      },
      "source": [
        "<h2>Table of Contents</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNvM6TLntp7t"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
        "\n",
        "\n",
        "<ul>\n",
        "    <li><a href=\"#download_data\"> Download Data</a></li>\n",
        "    <li><a href=\"#auxiliary\"> Imports and Auxiliary Functions </a></li>\n",
        "    <li><a href=\"#data_class\"> Dataset Class</a></li>\n",
        "    <li><a href=\"#Question_1\">Question 1</a></li>\n",
        "    <li><a href=\"#Question_2\">Question 2</a></li>\n",
        "    <li><a href=\"#Question_3\">Question 3</a></li>\n",
        "</ul>\n",
        "<p>Estimated Time Needed: <strong>120 min</strong></p>\n",
        " </div>\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiXx0iB6tp7t"
      },
      "source": [
        "<h2 id=\"download_data\">Download Data</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q12CLCWetp7u"
      },
      "source": [
        "Download the dataset and unzip the files in your data directory, unlike the other labs, all the data will be deleted after you close  the lab, this may take some time:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jndP5EYtp7u",
        "outputId": "fff7062b-5758-422d-e434-c972ffdb9669"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-04 16:15:44--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip\n",
            "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
            "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2598656062 (2.4G) [application/zip]\n",
            "Saving to: ‘Positive_tensors.zip’\n",
            "\n",
            "Positive_tensors.zi 100%[===================>]   2.42G  18.2MB/s    in 2m 19s  \n",
            "\n",
            "2025-07-04 16:18:04 (17.8 MB/s) - ‘Positive_tensors.zip’ saved [2598656062/2598656062]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip\n",
        "!unzip -qo Positive_tensors.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqGJqV3Btp7w",
        "outputId": "c538bc09-3be9-4247-ae0c-f461cfa4ec15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-04 16:20:45--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\n",
            "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
            "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2111408108 (2.0G) [application/zip]\n",
            "Saving to: ‘Negative_tensors.zip’\n",
            "\n",
            "Negative_tensors.zi 100%[===================>]   1.97G  3.99MB/s    in 7m 0s   \n",
            "\n",
            "2025-07-04 16:27:46 (4.79 MB/s) - ‘Negative_tensors.zip’ saved [2111408108/2111408108]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\n",
        "!unzip -qo Negative_tensors.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeZkC5Xdtp7w"
      },
      "source": [
        "We will install torchvision:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ov6km7P8tp7w",
        "outputId": "db9d8087-17ec-4b93-e6cc-2a723c7af4bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.6.0+cu124)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchvision) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m120.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWH2KC_Rtp7x"
      },
      "source": [
        "<h2 id=\"auxiliary\">Imports and Auxiliary Functions</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2GlXlXjtp7x"
      },
      "source": [
        "The following are the libraries we are going to use for this lab. The <code>torch.manual_seed()</code> is for forcing the random function to give the same number every time we try to recompile it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vV2qEn1-tp7x",
        "outputId": "7ea5f2d7-22e4-4aac-d395-ed1bc18caef7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7ab1681e46d0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# These are the libraries will be used for this lab.\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "import pandas\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import torch\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import h5py\n",
        "import os\n",
        "import glob\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "h4iskOHgtp7x"
      },
      "outputs": [],
      "source": [
        "from matplotlib.pyplot import imshow\n",
        "import matplotlib.pylab as plt\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCSeaOerOS5p",
        "outputId": "f7b05f46-da86-4d2e-cc55-983f3616bd20"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMKSDw-utp7x"
      },
      "source": [
        "<!--Empty Space for separating topics-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_qwTXfztp7x"
      },
      "source": [
        "<h2 id=\"data_class\">Dataset Class</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nU-_I2BGtp7x"
      },
      "source": [
        " This dataset class is essentially the same dataset you build in the previous section, but to speed things up, we are going to use tensors instead of jpeg images. Therefor for each iteration, you will skip the reshape step, conversion step to tensors and normalization step.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xr77d4Qotp7y",
        "outputId": "9bc30d59-19a0-4b7f-8069-3af1207db66a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ],
      "source": [
        "# Create your own dataset object\n",
        "\n",
        "class Dataset(Dataset):\n",
        "\n",
        "    # Constructor\n",
        "    def __init__(self,transform=None,train=True):\n",
        "        directory=\"/content\"\n",
        "        positive=\"Positive_tensors\"\n",
        "        negative='Negative_tensors'\n",
        "\n",
        "        positive_file_path=os.path.join(directory,positive)\n",
        "        negative_file_path=os.path.join(directory,negative)\n",
        "        positive_files=[os.path.join(positive_file_path,file) for file in os.listdir(positive_file_path) if file.endswith(\".pt\")]\n",
        "        negative_files=[os.path.join(negative_file_path,file) for file in os.listdir(negative_file_path) if file.endswith(\".pt\")]\n",
        "        number_of_samples=len(positive_files)+len(negative_files)\n",
        "        self.all_files=[None]*number_of_samples\n",
        "        self.all_files[::2]=positive_files\n",
        "        self.all_files[1::2]=negative_files\n",
        "        # The transform is goint to be used on image\n",
        "        self.transform = transform\n",
        "        #torch.LongTensor\n",
        "        self.Y=torch.zeros([number_of_samples]).type(torch.LongTensor)\n",
        "        self.Y[::2]=1\n",
        "        self.Y[1::2]=0\n",
        "\n",
        "        if train:\n",
        "            self.all_files=self.all_files[0:30000]\n",
        "            self.Y=self.Y[0:30000]\n",
        "            self.len=len(self.all_files)\n",
        "        else:\n",
        "            self.all_files=self.all_files[30000:]\n",
        "            self.Y=self.Y[30000:]\n",
        "            self.len=len(self.all_files)\n",
        "\n",
        "    # Get the length\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "    # Getter\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        image=torch.load(self.all_files[idx])\n",
        "        y=self.Y[idx]\n",
        "\n",
        "        # If there is any transform method, apply it onto the image\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, y\n",
        "\n",
        "print(\"done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPXPYcZXtp7y"
      },
      "source": [
        "We create two dataset objects, one for the training data and one for the validation data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gyg33a-etp7y",
        "outputId": "09f5be12-6a10-48be-983c-625aff9f4ea5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ],
      "source": [
        "train_dataset = Dataset(train=True)\n",
        "validation_dataset = Dataset(train=False)\n",
        "print(\"done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADumDcvFtp7y"
      },
      "source": [
        "<h2 id=\"Question_1\">Question 1</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brkCQtlltp7z"
      },
      "source": [
        "<b>Prepare a pre-trained resnet18 model :</b>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ib87WSektp7z"
      },
      "source": [
        "<b>Step 1</b>: Load the pre-trained model <code>resnet18</code> Set the parameter <code>pretrained</code> to true:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5WwBZqvtp7z",
        "outputId": "d58c47d3-0c8b-48e4-a292-1397067c635a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 52.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Load the pre-trained model resnet18\n",
        "# Type your code here\n",
        "model = models.resnet18(pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "cDKwJxGdPD_J"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C80pIpQltp7z"
      },
      "source": [
        "<b>Step 2</b>: Set the attribute <code>requires_grad</code> to <code>False</code>. As a result, the parameters will not be affected by training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "NPz2Mdywtp70"
      },
      "outputs": [],
      "source": [
        "# Step 2: Set the parameter cannot be trained for the pre-trained model\n",
        "\n",
        "\n",
        "# Type your code here\n",
        "for params in model.parameters():\n",
        "    params.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gMoYOAftp70"
      },
      "source": [
        "<code>resnet18</code> is used to classify 1000 different objects; as a result, the last layer has 1000 outputs.  The 512 inputs come from the fact that the previously hidden layer has 512 outputs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3q553DiOtp70"
      },
      "source": [
        "<b>Step 3</b>: Replace the output layer <code>model.fc</code> of the neural network with a <code>nn.Linear</code> object, to classify 2 different classes. For the parameters <code>in_features </code> remember the last hidden layer has 512 neurons.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "nFHQ14zftp70"
      },
      "outputs": [],
      "source": [
        "in_features = 512\n",
        "output_size = 2\n",
        "model.fc = nn.Linear(in_features, output_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot09S0i8tp70"
      },
      "source": [
        "Print out the model in order to show whether you get the correct answer.<br> <b>(Your peer reviewer is going to mark based on what you print here.)</b>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67ogrcmWtp70",
        "outputId": "9215dd02-a63a-46ac-f376-68ac039ae3f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for params in model.parameters():\n",
        "  if params.requires_grad:\n",
        "    print(params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hoKS8OsPKV4",
        "outputId": "8d64084a-71ca-440b-b426-be1b171ae4ca"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0409, -0.0068,  0.0387,  ..., -0.0134,  0.0123, -0.0107],\n",
            "        [ 0.0440, -0.0334, -0.0212,  ..., -0.0174, -0.0112,  0.0216]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0100, -0.0039], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "MMj6EUYwSYca"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2M5xCNAtp70"
      },
      "source": [
        "<h2 id=\"Question_2\">Question 2: Train the Model</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hw5KOmBtp71"
      },
      "source": [
        "In this question you will train your, model:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5b8Dc3jtp71"
      },
      "source": [
        "<b>Step 1</b>: Create a cross entropy criterion function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "iDgKJXcQtp71"
      },
      "outputs": [],
      "source": [
        "# Step 1: Create the loss function\n",
        "\n",
        "# Type your code here\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0j66o2Rqtp71"
      },
      "source": [
        "<b>Step 2</b>: Create a training loader and validation loader object, the batch size should have 100 samples each.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "nkwJMnF5tp8J"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=100)\n",
        "val_loader = DataLoader(validation_dataset, batch_size=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB6fap2htp8J"
      },
      "source": [
        "<b>Step 3</b>: Use the following optimizer to minimize the loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "o2Bly93ktp8J"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam([parameters  for parameters in model.parameters() if parameters.requires_grad],lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTVQzulMtp8J"
      },
      "source": [
        "<!--Empty Space for separating topics-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjVt9lBTtp8K"
      },
      "source": [
        "**Complete the following code to calculate  the accuracy on the validation data for one epoch; this should take about 45 minutes. Make sure you calculate the accuracy on the validation data.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24SF4cu6tp8K",
        "outputId": "bfebfa9f-ace7-4af0-a12e-09780a77f9cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: tensor(0.7546, device='cuda:0')\n",
            "loss: tensor(0.7358, device='cuda:0')\n",
            "loss: tensor(0.7183, device='cuda:0')\n",
            "loss: tensor(0.6322, device='cuda:0')\n",
            "loss: tensor(0.5627, device='cuda:0')\n",
            "loss: tensor(0.5009, device='cuda:0')\n",
            "loss: tensor(0.5106, device='cuda:0')\n",
            "loss: tensor(0.4847, device='cuda:0')\n",
            "loss: tensor(0.4462, device='cuda:0')\n",
            "loss: tensor(0.4244, device='cuda:0')\n",
            "loss: tensor(0.4137, device='cuda:0')\n",
            "loss: tensor(0.3795, device='cuda:0')\n",
            "loss: tensor(0.3261, device='cuda:0')\n",
            "loss: tensor(0.3384, device='cuda:0')\n",
            "loss: tensor(0.3199, device='cuda:0')\n",
            "loss: tensor(0.2961, device='cuda:0')\n",
            "loss: tensor(0.2677, device='cuda:0')\n",
            "loss: tensor(0.2921, device='cuda:0')\n",
            "loss: tensor(0.2453, device='cuda:0')\n",
            "loss: tensor(0.2601, device='cuda:0')\n",
            "loss: tensor(0.2221, device='cuda:0')\n",
            "loss: tensor(0.2479, device='cuda:0')\n",
            "loss: tensor(0.2114, device='cuda:0')\n",
            "loss: tensor(0.2351, device='cuda:0')\n",
            "loss: tensor(0.2218, device='cuda:0')\n",
            "loss: tensor(0.1985, device='cuda:0')\n",
            "loss: tensor(0.1910, device='cuda:0')\n",
            "loss: tensor(0.1701, device='cuda:0')\n",
            "loss: tensor(0.2112, device='cuda:0')\n",
            "loss: tensor(0.1435, device='cuda:0')\n",
            "loss: tensor(0.1531, device='cuda:0')\n",
            "loss: tensor(0.1509, device='cuda:0')\n",
            "loss: tensor(0.1421, device='cuda:0')\n",
            "loss: tensor(0.1527, device='cuda:0')\n",
            "loss: tensor(0.1591, device='cuda:0')\n",
            "loss: tensor(0.1400, device='cuda:0')\n",
            "loss: tensor(0.1510, device='cuda:0')\n",
            "loss: tensor(0.1582, device='cuda:0')\n",
            "loss: tensor(0.1322, device='cuda:0')\n",
            "loss: tensor(0.1518, device='cuda:0')\n",
            "loss: tensor(0.1110, device='cuda:0')\n",
            "loss: tensor(0.1217, device='cuda:0')\n",
            "loss: tensor(0.1260, device='cuda:0')\n",
            "loss: tensor(0.1641, device='cuda:0')\n",
            "loss: tensor(0.1344, device='cuda:0')\n",
            "loss: tensor(0.1415, device='cuda:0')\n",
            "loss: tensor(0.1288, device='cuda:0')\n",
            "loss: tensor(0.1018, device='cuda:0')\n",
            "loss: tensor(0.1398, device='cuda:0')\n",
            "loss: tensor(0.0957, device='cuda:0')\n",
            "loss: tensor(0.1203, device='cuda:0')\n",
            "loss: tensor(0.1028, device='cuda:0')\n",
            "loss: tensor(0.1110, device='cuda:0')\n",
            "loss: tensor(0.0831, device='cuda:0')\n",
            "loss: tensor(0.1074, device='cuda:0')\n",
            "loss: tensor(0.0972, device='cuda:0')\n",
            "loss: tensor(0.0912, device='cuda:0')\n",
            "loss: tensor(0.1100, device='cuda:0')\n",
            "loss: tensor(0.1132, device='cuda:0')\n",
            "loss: tensor(0.1167, device='cuda:0')\n",
            "loss: tensor(0.0811, device='cuda:0')\n",
            "loss: tensor(0.0776, device='cuda:0')\n",
            "loss: tensor(0.0888, device='cuda:0')\n",
            "loss: tensor(0.1016, device='cuda:0')\n",
            "loss: tensor(0.0694, device='cuda:0')\n",
            "loss: tensor(0.0778, device='cuda:0')\n",
            "loss: tensor(0.0719, device='cuda:0')\n",
            "loss: tensor(0.0617, device='cuda:0')\n",
            "loss: tensor(0.0665, device='cuda:0')\n",
            "loss: tensor(0.0918, device='cuda:0')\n",
            "loss: tensor(0.0771, device='cuda:0')\n",
            "loss: tensor(0.0756, device='cuda:0')\n",
            "loss: tensor(0.0576, device='cuda:0')\n",
            "loss: tensor(0.0856, device='cuda:0')\n",
            "loss: tensor(0.0594, device='cuda:0')\n",
            "loss: tensor(0.0794, device='cuda:0')\n",
            "loss: tensor(0.0563, device='cuda:0')\n",
            "loss: tensor(0.0691, device='cuda:0')\n",
            "loss: tensor(0.0940, device='cuda:0')\n",
            "loss: tensor(0.0763, device='cuda:0')\n",
            "loss: tensor(0.0942, device='cuda:0')\n",
            "loss: tensor(0.0902, device='cuda:0')\n",
            "loss: tensor(0.0742, device='cuda:0')\n",
            "loss: tensor(0.0483, device='cuda:0')\n",
            "loss: tensor(0.0614, device='cuda:0')\n",
            "loss: tensor(0.0578, device='cuda:0')\n",
            "loss: tensor(0.0611, device='cuda:0')\n",
            "loss: tensor(0.0689, device='cuda:0')\n",
            "loss: tensor(0.0794, device='cuda:0')\n",
            "loss: tensor(0.0725, device='cuda:0')\n",
            "loss: tensor(0.0635, device='cuda:0')\n",
            "loss: tensor(0.0588, device='cuda:0')\n",
            "loss: tensor(0.0764, device='cuda:0')\n",
            "loss: tensor(0.0666, device='cuda:0')\n",
            "loss: tensor(0.0640, device='cuda:0')\n",
            "loss: tensor(0.0474, device='cuda:0')\n",
            "loss: tensor(0.0659, device='cuda:0')\n",
            "loss: tensor(0.0813, device='cuda:0')\n",
            "loss: tensor(0.0399, device='cuda:0')\n",
            "loss: tensor(0.0577, device='cuda:0')\n",
            "loss: tensor(0.0463, device='cuda:0')\n",
            "loss: tensor(0.0885, device='cuda:0')\n",
            "loss: tensor(0.0612, device='cuda:0')\n",
            "loss: tensor(0.0561, device='cuda:0')\n",
            "loss: tensor(0.0761, device='cuda:0')\n",
            "loss: tensor(0.0566, device='cuda:0')\n",
            "loss: tensor(0.0969, device='cuda:0')\n",
            "loss: tensor(0.0362, device='cuda:0')\n",
            "loss: tensor(0.0494, device='cuda:0')\n",
            "loss: tensor(0.0410, device='cuda:0')\n",
            "loss: tensor(0.0711, device='cuda:0')\n",
            "loss: tensor(0.0570, device='cuda:0')\n",
            "loss: tensor(0.0898, device='cuda:0')\n",
            "loss: tensor(0.0435, device='cuda:0')\n",
            "loss: tensor(0.0512, device='cuda:0')\n",
            "loss: tensor(0.0697, device='cuda:0')\n",
            "loss: tensor(0.0956, device='cuda:0')\n",
            "loss: tensor(0.0526, device='cuda:0')\n",
            "loss: tensor(0.0534, device='cuda:0')\n",
            "loss: tensor(0.0538, device='cuda:0')\n",
            "loss: tensor(0.0438, device='cuda:0')\n",
            "loss: tensor(0.0498, device='cuda:0')\n",
            "loss: tensor(0.0616, device='cuda:0')\n",
            "loss: tensor(0.0531, device='cuda:0')\n",
            "loss: tensor(0.0684, device='cuda:0')\n",
            "loss: tensor(0.0497, device='cuda:0')\n",
            "loss: tensor(0.0553, device='cuda:0')\n",
            "loss: tensor(0.0465, device='cuda:0')\n",
            "loss: tensor(0.0493, device='cuda:0')\n",
            "loss: tensor(0.1195, device='cuda:0')\n",
            "loss: tensor(0.0648, device='cuda:0')\n",
            "loss: tensor(0.0257, device='cuda:0')\n",
            "loss: tensor(0.0557, device='cuda:0')\n",
            "loss: tensor(0.0378, device='cuda:0')\n",
            "loss: tensor(0.0486, device='cuda:0')\n",
            "loss: tensor(0.0446, device='cuda:0')\n",
            "loss: tensor(0.0424, device='cuda:0')\n",
            "loss: tensor(0.0847, device='cuda:0')\n",
            "loss: tensor(0.0416, device='cuda:0')\n",
            "loss: tensor(0.0382, device='cuda:0')\n",
            "loss: tensor(0.0543, device='cuda:0')\n",
            "loss: tensor(0.0753, device='cuda:0')\n",
            "loss: tensor(0.0560, device='cuda:0')\n",
            "loss: tensor(0.0449, device='cuda:0')\n",
            "loss: tensor(0.0555, device='cuda:0')\n",
            "loss: tensor(0.0451, device='cuda:0')\n",
            "loss: tensor(0.0650, device='cuda:0')\n",
            "loss: tensor(0.0429, device='cuda:0')\n",
            "loss: tensor(0.0509, device='cuda:0')\n",
            "loss: tensor(0.0418, device='cuda:0')\n",
            "loss: tensor(0.0332, device='cuda:0')\n",
            "loss: tensor(0.0357, device='cuda:0')\n",
            "loss: tensor(0.0318, device='cuda:0')\n",
            "loss: tensor(0.0630, device='cuda:0')\n",
            "loss: tensor(0.0425, device='cuda:0')\n",
            "loss: tensor(0.0379, device='cuda:0')\n",
            "loss: tensor(0.0793, device='cuda:0')\n",
            "loss: tensor(0.0387, device='cuda:0')\n",
            "loss: tensor(0.0486, device='cuda:0')\n",
            "loss: tensor(0.0423, device='cuda:0')\n",
            "loss: tensor(0.0301, device='cuda:0')\n",
            "loss: tensor(0.0532, device='cuda:0')\n",
            "loss: tensor(0.0393, device='cuda:0')\n",
            "loss: tensor(0.0364, device='cuda:0')\n",
            "loss: tensor(0.0622, device='cuda:0')\n",
            "loss: tensor(0.0552, device='cuda:0')\n",
            "loss: tensor(0.0447, device='cuda:0')\n",
            "loss: tensor(0.0409, device='cuda:0')\n",
            "loss: tensor(0.0379, device='cuda:0')\n",
            "loss: tensor(0.0482, device='cuda:0')\n",
            "loss: tensor(0.0506, device='cuda:0')\n",
            "loss: tensor(0.0351, device='cuda:0')\n",
            "loss: tensor(0.0301, device='cuda:0')\n",
            "loss: tensor(0.0233, device='cuda:0')\n",
            "loss: tensor(0.0295, device='cuda:0')\n",
            "loss: tensor(0.0459, device='cuda:0')\n",
            "loss: tensor(0.0367, device='cuda:0')\n",
            "loss: tensor(0.0403, device='cuda:0')\n",
            "loss: tensor(0.0311, device='cuda:0')\n",
            "loss: tensor(0.0355, device='cuda:0')\n",
            "loss: tensor(0.0364, device='cuda:0')\n",
            "loss: tensor(0.0657, device='cuda:0')\n",
            "loss: tensor(0.0236, device='cuda:0')\n",
            "loss: tensor(0.0485, device='cuda:0')\n",
            "loss: tensor(0.0376, device='cuda:0')\n",
            "loss: tensor(0.0485, device='cuda:0')\n",
            "loss: tensor(0.0383, device='cuda:0')\n",
            "loss: tensor(0.0452, device='cuda:0')\n",
            "loss: tensor(0.0558, device='cuda:0')\n",
            "loss: tensor(0.0511, device='cuda:0')\n",
            "loss: tensor(0.0220, device='cuda:0')\n",
            "loss: tensor(0.0211, device='cuda:0')\n",
            "loss: tensor(0.0405, device='cuda:0')\n",
            "loss: tensor(0.0559, device='cuda:0')\n",
            "loss: tensor(0.0225, device='cuda:0')\n",
            "loss: tensor(0.0428, device='cuda:0')\n",
            "loss: tensor(0.0536, device='cuda:0')\n",
            "loss: tensor(0.0291, device='cuda:0')\n",
            "loss: tensor(0.0268, device='cuda:0')\n",
            "loss: tensor(0.0245, device='cuda:0')\n",
            "loss: tensor(0.0222, device='cuda:0')\n",
            "loss: tensor(0.0318, device='cuda:0')\n",
            "loss: tensor(0.0440, device='cuda:0')\n",
            "loss: tensor(0.0320, device='cuda:0')\n",
            "loss: tensor(0.0311, device='cuda:0')\n",
            "loss: tensor(0.0425, device='cuda:0')\n",
            "loss: tensor(0.0355, device='cuda:0')\n",
            "loss: tensor(0.0287, device='cuda:0')\n",
            "loss: tensor(0.0216, device='cuda:0')\n",
            "loss: tensor(0.0233, device='cuda:0')\n",
            "loss: tensor(0.0263, device='cuda:0')\n",
            "loss: tensor(0.0341, device='cuda:0')\n",
            "loss: tensor(0.0337, device='cuda:0')\n",
            "loss: tensor(0.0481, device='cuda:0')\n",
            "loss: tensor(0.0254, device='cuda:0')\n",
            "loss: tensor(0.0221, device='cuda:0')\n",
            "loss: tensor(0.0262, device='cuda:0')\n",
            "loss: tensor(0.0355, device='cuda:0')\n",
            "loss: tensor(0.0177, device='cuda:0')\n",
            "loss: tensor(0.0354, device='cuda:0')\n",
            "loss: tensor(0.0162, device='cuda:0')\n",
            "loss: tensor(0.0473, device='cuda:0')\n",
            "loss: tensor(0.0258, device='cuda:0')\n",
            "loss: tensor(0.0221, device='cuda:0')\n",
            "loss: tensor(0.0310, device='cuda:0')\n",
            "loss: tensor(0.0337, device='cuda:0')\n",
            "loss: tensor(0.0389, device='cuda:0')\n",
            "loss: tensor(0.0252, device='cuda:0')\n",
            "loss: tensor(0.0165, device='cuda:0')\n",
            "loss: tensor(0.0293, device='cuda:0')\n",
            "loss: tensor(0.0278, device='cuda:0')\n",
            "loss: tensor(0.0374, device='cuda:0')\n",
            "loss: tensor(0.0346, device='cuda:0')\n",
            "loss: tensor(0.0567, device='cuda:0')\n",
            "loss: tensor(0.0376, device='cuda:0')\n",
            "loss: tensor(0.0274, device='cuda:0')\n",
            "loss: tensor(0.0447, device='cuda:0')\n",
            "loss: tensor(0.0334, device='cuda:0')\n",
            "loss: tensor(0.0320, device='cuda:0')\n",
            "loss: tensor(0.0215, device='cuda:0')\n",
            "loss: tensor(0.0386, device='cuda:0')\n",
            "loss: tensor(0.0420, device='cuda:0')\n",
            "loss: tensor(0.0402, device='cuda:0')\n",
            "loss: tensor(0.0294, device='cuda:0')\n",
            "loss: tensor(0.0215, device='cuda:0')\n",
            "loss: tensor(0.0522, device='cuda:0')\n",
            "loss: tensor(0.0253, device='cuda:0')\n",
            "loss: tensor(0.0515, device='cuda:0')\n",
            "loss: tensor(0.0183, device='cuda:0')\n",
            "loss: tensor(0.0209, device='cuda:0')\n",
            "loss: tensor(0.0275, device='cuda:0')\n",
            "loss: tensor(0.0228, device='cuda:0')\n",
            "loss: tensor(0.0498, device='cuda:0')\n",
            "loss: tensor(0.0380, device='cuda:0')\n",
            "loss: tensor(0.0182, device='cuda:0')\n",
            "loss: tensor(0.0419, device='cuda:0')\n",
            "loss: tensor(0.0214, device='cuda:0')\n",
            "loss: tensor(0.0372, device='cuda:0')\n",
            "loss: tensor(0.0217, device='cuda:0')\n",
            "loss: tensor(0.0368, device='cuda:0')\n",
            "loss: tensor(0.0383, device='cuda:0')\n",
            "loss: tensor(0.0280, device='cuda:0')\n",
            "loss: tensor(0.0389, device='cuda:0')\n",
            "loss: tensor(0.0556, device='cuda:0')\n",
            "loss: tensor(0.0496, device='cuda:0')\n",
            "loss: tensor(0.0269, device='cuda:0')\n",
            "loss: tensor(0.0414, device='cuda:0')\n",
            "loss: tensor(0.0264, device='cuda:0')\n",
            "loss: tensor(0.0393, device='cuda:0')\n",
            "loss: tensor(0.0199, device='cuda:0')\n",
            "loss: tensor(0.0348, device='cuda:0')\n",
            "loss: tensor(0.0441, device='cuda:0')\n",
            "loss: tensor(0.0387, device='cuda:0')\n",
            "loss: tensor(0.0625, device='cuda:0')\n",
            "loss: tensor(0.0374, device='cuda:0')\n",
            "loss: tensor(0.0381, device='cuda:0')\n",
            "loss: tensor(0.0389, device='cuda:0')\n",
            "loss: tensor(0.0209, device='cuda:0')\n",
            "loss: tensor(0.0484, device='cuda:0')\n",
            "loss: tensor(0.0505, device='cuda:0')\n",
            "loss: tensor(0.0209, device='cuda:0')\n",
            "loss: tensor(0.0265, device='cuda:0')\n",
            "loss: tensor(0.0184, device='cuda:0')\n",
            "loss: tensor(0.0416, device='cuda:0')\n",
            "loss: tensor(0.0255, device='cuda:0')\n",
            "loss: tensor(0.0267, device='cuda:0')\n",
            "loss: tensor(0.0239, device='cuda:0')\n",
            "loss: tensor(0.0228, device='cuda:0')\n",
            "loss: tensor(0.0219, device='cuda:0')\n",
            "loss: tensor(0.0244, device='cuda:0')\n",
            "loss: tensor(0.0169, device='cuda:0')\n",
            "loss: tensor(0.0201, device='cuda:0')\n",
            "loss: tensor(0.0319, device='cuda:0')\n",
            "loss: tensor(0.0220, device='cuda:0')\n",
            "loss: tensor(0.0177, device='cuda:0')\n",
            "loss: tensor(0.0169, device='cuda:0')\n",
            "loss: tensor(0.0220, device='cuda:0')\n",
            "loss: tensor(0.0351, device='cuda:0')\n",
            "loss: tensor(0.0500, device='cuda:0')\n",
            "loss: tensor(0.0292, device='cuda:0')\n",
            "Total Time is given in minutes  4.437198408444723\n"
          ]
        }
      ],
      "source": [
        "n_epochs=1\n",
        "loss_list=[]\n",
        "accuracy_list=[]\n",
        "correct=0\n",
        "N_test=len(validation_dataset)\n",
        "N_train=len(train_dataset)\n",
        "start_time = time.time()\n",
        "#n_epochs = 5\n",
        "\n",
        "Loss=0\n",
        "start_time = time.time()\n",
        "for epoch in range(n_epochs):\n",
        "    for x, y in train_loader:\n",
        "        x=x.to(device)\n",
        "        y=y.to(device)\n",
        "        model.train()\n",
        "        #clear gradient\n",
        "        optimizer.zero_grad()\n",
        "        #make a prediction\n",
        "        z = model(x)\n",
        "\n",
        "        # calculate loss\n",
        "        loss = criterion(z, y)\n",
        "        # calculate gradients of parameters\n",
        "        loss.backward()\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "        loss_list.append(loss.data)\n",
        "        print('loss:',loss.data)\n",
        "    correct=0\n",
        "    for x_test, y_test in val_loader:\n",
        "        x_test=x_test.to(device)\n",
        "        y_test=y_test.to(device)\n",
        "        # set model to eval\n",
        "        model.eval()\n",
        "        #make a prediction\n",
        "        z = model(x_test)\n",
        "        #find max\n",
        "        _, yhat = torch.max(z.data, 1)\n",
        "\n",
        "        #Calculate misclassified  samples in mini-batch\n",
        "        #hint +=(yhat==y_test).sum().item()\n",
        "        correct += (yhat ==y_test).sum().item()\n",
        "\n",
        "    accuracy=correct/N_test\n",
        "    accuracy_list.append(accuracy)\n",
        "\n",
        "    # save best model\n",
        "    if accuracy==max(accuracy_list):\n",
        "        torch.save(model.state_dict(), 'best_model.pt')\n",
        "        best_accuracy = accuracy\n",
        "\n",
        "print(\"Total Time is given in minutes \", (time.time() - start_time)/60)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfdeMN6ctp8K"
      },
      "source": [
        "<b>Print out the Accuracy and plot the loss stored in the list <code>loss_list</code> for every iteration and take a screen shot.</b>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kA7n8_T2tp8K",
        "outputId": "f405f428-12f6-475b-9ef4-735747825da5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9927"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "to-5mlC8tp8K",
        "outputId": "2c071d72-9887-49e8-b145-be69ca450797"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "loss_values = [loss.cpu().item() if torch.is_tensor(loss) else loss for loss in loss_list]\n",
        "\n",
        "plt.plot(loss_values)\n",
        "plt.xlabel(\"iteration\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5RZuoc6tp8K"
      },
      "source": [
        "<h2 id=\"Question_3\">Question 3:Find the misclassified samples</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUkkU7IYtp8K"
      },
      "source": [
        "<b>Identify the first four misclassified samples using the validation data:</b>\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "misclassified_count = 0\n",
        "sample_index = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x_val, y_val in val_loader:\n",
        "        x_val = x_val.to(device)\n",
        "        y_val = y_val.to(device)\n",
        "        outputs = model(x_val)\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "        for i in range(len(y_val)):\n",
        "            predicted = preds[i]\n",
        "            actual = y_val[i]\n",
        "            if predicted != actual:\n",
        "                print(f\"sample{sample_index} predicted value: {predicted.unsqueeze(0)}  actual value: {actual.unsqueeze(0)}\")\n",
        "                misclassified_count += 1\n",
        "                if misclassified_count == 4:\n",
        "                    break\n",
        "            sample_index += 1\n",
        "        if misclassified_count == 4:\n",
        "            break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPJhb_EBd1bW",
        "outputId": "c945114c-cd07-4540-899c-f70e87fcfeb1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample190 predicted value: tensor([0], device='cuda:0')  actual value: tensor([1], device='cuda:0')\n",
            "sample504 predicted value: tensor([0], device='cuda:0')  actual value: tensor([1], device='cuda:0')\n",
            "sample530 predicted value: tensor([0], device='cuda:0')  actual value: tensor([1], device='cuda:0')\n",
            "sample561 predicted value: tensor([1], device='cuda:0')  actual value: tensor([0], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCf9J7aDtp8K"
      },
      "source": [
        "<a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/share-notebooks.html?utm_source=skills_network&utm_content=in_lab_content_link&utm_id=Lab-IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork\"> CLICK HERE </a> Click here to see how to share your notebook.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nk106t6atp8K"
      },
      "source": [
        "<h2>About the Authors:</h2>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgNcoZr4tp8L"
      },
      "source": [
        "\n",
        "## Change Log\n",
        "\n",
        "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
        "|---|---|---|---|\n",
        "| 2020-09-21  | 2.0  | Shubham  |  Migrated Lab to Markdown and added to course repo in GitLab |\n",
        "\n",
        "\n",
        "\n",
        "<hr>\n",
        "\n",
        "## <h3 align=\"center\"> © IBM Corporation 2020. All rights reserved. <h3/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yz_x-UaGtp8L"
      },
      "source": [
        "Copyright &copy; 2018 <a href=\"cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu\">cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\">MIT License</a>.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "conda-env-python-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "prev_pub_hash": "411ae2aef8ceb1100f8902a4d5f03fa3959d6f13ed71b4e07911db0399a6abc3",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}